{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "0F7wUB5zrPAG"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Dropout, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "class TextCNN:\n",
    "    def __init__(self, num_classes, vocab_size, embedding_dim, filter_sizes, num_filters, dropout_rate):\n",
    "        self.num_classes = num_classes\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.num_filters = num_filters\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def build(self, sequence_length):\n",
    "        inputs = Input(shape=(sequence_length,), dtype='int32')\n",
    "        embedding = hub.KerasLayer(\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\", trainable=True)(inputs)\n",
    "        reshape = tf.reshape(embedding, shape=[-1, sequence_length, self.embedding_dim, 1])\n",
    "        \n",
    "        conv_0 = Conv1D(self.num_filters, self.filter_sizes[0], activation='relu')(reshape)\n",
    "        conv_1 = Conv1D(self.num_filters, self.filter_sizes[1], activation='relu')(reshape)\n",
    "        conv_2 = Conv1D(self.num_filters, self.filter_sizes[2], activation='relu')(reshape)\n",
    "        \n",
    "        maxpool_0 = MaxPooling1D(sequence_length - self.filter_sizes[0] + 1)(conv_0)\n",
    "        maxpool_1 = MaxPooling1D(sequence_length - self.filter_sizes[1] + 1)(conv_1)\n",
    "        maxpool_2 = MaxPooling1D(sequence_length - self.filter_sizes[2] + 1)(conv_2)\n",
    "        \n",
    "        concatenated_tensor = concatenate([maxpool_0, maxpool_1, maxpool_2], axis=1)\n",
    "        flatten = tf.reshape(concatenated_tensor, shape=[-1, 3 * self.num_filters])\n",
    "        dropout = Dropout(self.dropout_rate)(flatten)\n",
    "        output = tf.keras.layers.Dense(self.num_classes, activation='sigmoid')(dropout)\n",
    "\n",
    "        model = Model(inputs, output)\n",
    "        return model\n",
    "\n",
    "\n",
    "class SiameseNetwork:\n",
    "    def __init__(self, textcnn):\n",
    "        self.textcnn = textcnn\n",
    "\n",
    "    def build(self, sequence_length):\n",
    "        left_input = Input(shape=(sequence_length,), dtype='int32')\n",
    "        right_input = Input(shape=(sequence_length,), dtype='int32')\n",
    "\n",
    "        encoded_left = self.textcnn.build(sequence_length)(left_input)\n",
    "        encoded_right = self.textcnn.build(sequence_length)(right_input)\n",
    "        \n",
    "        l1_distance = tf.keras.layers.Lambda(self.manhattan_distance, output_shape=self.euclidean_distance_output_shape)([encoded_left, encoded_right])\n",
    "\n",
    "        prediction = tf.keras.layers.Dense(1, activation='sigmoid')(l1_distance)\n",
    "        model = Model([left_input, right_input], prediction)\n",
    "        return model\n",
    "\n",
    "    def manhattan_distance(self, inputs):\n",
    "        x, y = inputs\n",
    "        return tf.keras.backend.exp(-tf.keras.backend.sum(tf.keras.backend.abs(x - y), axis=1, keepdims=True))\n",
    "\n",
    "    def euclidean_distance_output_shape(self, shapes):\n",
    "        shape1, shape2 = shapes\n",
    "        return (shape1[0], 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "90nSKGrquKNY"
   },
   "outputs": [],
   "source": [
    "csv_file = \"/content/pairs.csv\"\n",
    "csv_data = pd.read_csv(csv_file, low_memory = False)#防止弹出警告\n",
    "pairs = pd.DataFrame(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N7AJNaZJuVfy"
   },
   "outputs": [],
   "source": [
    "part_60 = pairs.sample(frac = 0.6)\n",
    "\n",
    "part_40 = pairs.drop(part_60.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "y6OUyDdAyjv3"
   },
   "outputs": [],
   "source": [
    "train = part_60\n",
    "test = part_40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "fvPWEfaXzBr4"
   },
   "outputs": [],
   "source": [
    "train =[part_60['bug1'].values,part_60['bug2'].values]\n",
    "test =[part_40['bug1'].values,part_40['bug2'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "a_KK0MSnzXiq"
   },
   "outputs": [],
   "source": [
    "train_label = part_60['label'].values\n",
    "test_label = part_40['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "8S8-iZrLzjxO"
   },
   "outputs": [],
   "source": [
    "train_label = np.where(train_label == -1, 0, train_label)\n",
    "test_label = np.where(test_label == -1, 0, test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "BkvMFANxuKbj",
    "outputId": "0afb877c-9c01-4b7b-de75-6e8c883bb4a9"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-4b933f995d38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-4b933f995d38>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtextcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msiamese_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSiameseNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextcnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiamese_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-13a7db3d5283>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, sequence_length)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mright_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mencoded_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mencoded_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-13a7db3d5283>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, sequence_length)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mreshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                        \"a signature (or using a legacy TF1 Hub format).\")\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m_get_callable\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m                        \"saved models (if not legacy TF1 Hub format).\")\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_signature\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m       raise ValueError(\"Unknown signature %s in %s (available signatures: %s).\"\n\u001b[0m\u001b[1;32m    303\u001b[0m                        % (self._signature, self._handle, self._func.signatures))\n\u001b[1;32m    304\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_signature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown signature default in https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1 (available signatures: _SignatureMap({'tokenization_info': <ConcreteFunction pruned() at 0x7F78DCAB4FA0>, 'mlm': <ConcreteFunction pruned(input_ids, input_mask, mlm_positions, segment_ids) at 0x7F78DCAAE400>, 'tokens': <ConcreteFunction pruned(input_ids, input_mask, segment_ids) at 0x7F78D6F38190>}))."
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # TextCNN hyper-parameters\n",
    "    num_classes = 2\n",
    "    vocab_size = 10000\n",
    "    embedding_dim = 768\n",
    "    filter_sizes = [3, 4, 5]\n",
    "    num_filters = 100\n",
    "    dropout_rate = 0.5\n",
    "\n",
    "    # SiameseNetwork hyper-parameters\n",
    "    sequence_length = 30\n",
    "    batch_size = 128\n",
    "    epochs = 20\n",
    "    \n",
    "    textcnn = TextCNN(num_classes, vocab_size, embedding_dim, filter_sizes, num_filters, dropout_rate)\n",
    "    siamese_network = SiameseNetwork(textcnn)\n",
    "    model = siamese_network.build(sequence_length)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Load your data here and start training\n",
    "    # ...\n",
    "    model.fit(train, train_label, batch_size=batch_size, epochs=epochs, validation_data=(test, test_label))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
